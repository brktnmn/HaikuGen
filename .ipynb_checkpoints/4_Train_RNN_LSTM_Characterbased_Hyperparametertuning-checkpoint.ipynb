{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfb0df2-6691-42f0-a537-06a1ffbfd9a7",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7d1ec-28ab-4353-9de5-9d0102b0d061",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203148e5-af60-4988-b678-bda538d6249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11804/3953883262.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4acdb5f-346c-45c3-afcb-b8af2ec10aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 13:38:18.998356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:19.045548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:19.046063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d02a6e-d7e4-49bb-85a8-db2d70189bb6",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c39059e-77d5-42d6-bdce-766e49e9f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz einlesen\n",
    "df = pd.read_csv('data/out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd8388-e4bc-4b0b-b6f2-c8ab37360f92",
   "metadata": {},
   "source": [
    "## Transform dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19816b9-d18a-4c52-bda3-7aef12cb0867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframe mit 3 Spalten. Werden so gejoint, dass ein neues Dataframe mit ein Haiku pro Zeile erstellt wird\n",
    "df = df[['0', '1', '2']].agg(lambda x: '\\n'.join(x.values), axis=1)\n",
    "# Dataframe to list [[]] -> []\n",
    "array_of_poems = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2726013-e79e-4d25-b5da-a0fc4e2c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_poems an Haikus mit Semicolon zwshceneinander zusammenfuegen\n",
    "num_poems = 10000\n",
    "\n",
    "text = ';'.join(array_of_poems[:num_poems])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34535e9-892b-41b4-b2cb-a89c60fdfcfb",
   "metadata": {},
   "source": [
    "## Get unique chars in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d688c4-b56f-46fc-a88c-862b2ef63d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 unique chars\n",
      "['\\n', ' ', ';', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Anzahl der unterschielichen characters im gesamt datensatz herausfinden\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "print(f'{vocab_size} unique chars')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc70bbf-d679-4605-9da5-a35f29f57a1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c70db9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 29\n",
      "Number of sequences: 60004\n"
     ]
    }
   ],
   "source": [
    "print(\"Total chars:\", vocab_size)\n",
    "# Dictionary erstellen. Jeder character wird mit einer Zahl nummeriert\n",
    "char_indices = {c: i for i, c in enumerate(vocab)}\n",
    "indices_char = {i: c for i, c in enumerate(vocab)}\n",
    "\n",
    "# cut the text in semi-redundant sequences of seq_len characters\n",
    "seq_len = 150\n",
    "step = 11\n",
    "# Input String\n",
    "sequences = []\n",
    "#Output character\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sequences.append(text[i : i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print(\"Number of sequences:\", len(sequences))\n",
    "\n",
    "# Input String onehot encoded\n",
    "x = np.zeros((len(sequences), seq_len, vocab_size), dtype=bool)\n",
    "# Output char onehot encoded\n",
    "y = np.zeros((len(sequences), vocab_size), dtype=bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c82072d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cd1aa7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f81d86-3722-4859-b4a0-f2af92b9e4a7",
   "metadata": {},
   "source": [
    "## Hyperparametertuning / Model Optimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f28f5eb-88a2-45e7-a4e9-98f7d185b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f43227f-1cfc-40e3-8974-4942dd74de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(hp.Int('input_unit', min_value=32, max_value=512, step=32), \n",
    "                        input_shape=(x.shape[1], x.shape[2]), \n",
    "                        dropout=hp.Float('Dropout_rate',min_value=0.1,max_value=0.5,step=0.1),\n",
    "                        return_sequences=True)\n",
    "             )\n",
    "    for i in range(hp.Int('n_layers', 1, 2)):\n",
    "        model.add(layers.LSTM(hp.Int(f'lstm_{i}_units', min_value=32, max_value=512, step=32),  \n",
    "                            dropout=hp.Float('Dropout_rate',min_value=0.1,max_value=0.5,step=0.1),\n",
    "                            return_sequences=True)\n",
    "                 )\n",
    "    model.add(layers.LSTM(hp.Int('layer_2_neurons', min_value=32, max_value=512, step=32)))      \n",
    "    model.add(layers.Dense(vocab_size, activation=hp.Choice('dense_activation', values=['relu', 'sigmoid'], default='relu')))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics = ['accuracy'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04c88e7-9cd6-475a-95d5-a043ba759d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 13:38:29.521672: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 13:38:29.523029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:29.523700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:29.524086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:30.456729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:30.457298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:30.457795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-09 13:38:30.458149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6114 MB memory:  -> device: 0, name: GRID V100S-8Q, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "tuner= RandomSearch(\n",
    "        build_model,\n",
    "        max_trials=10,\n",
    "        objective=\"accuracy\",\n",
    "        executions_per_trial=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bccc4bd-ef0e-49f8-ab1f-056f8f59320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 53s]\n",
      "accuracy: 0.17237183451652527\n",
      "\n",
      "Best accuracy So Far: 0.24663355946540833\n",
      "Total elapsed time: 00h 09m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        epochs=3,\n",
    "        batch_size=512,\n",
    "        #validation_data=(x, y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bab515a-cec9-45e5-87cd-bc9c6cb07714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5b39dc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         # input_shape=sequenz laenge, vocab_size\n",
    "#         # return sequences true -> input-shape = output-shape \n",
    "#         # shape-input (NONE, seq_len, vocab_size)\n",
    "#         layers.LSTM(256, input_shape=(x.shape[1], x.shape[2]), return_sequences=True),\n",
    "#         layers.Dropout(0.2),\n",
    "#         # shape-input (NONE, seq_len, vocab_size)\n",
    "#         layers.LSTM(128, return_sequences=True),\n",
    "#         layers.Dropout(0.2),\n",
    "#         # shape-input (NONE, seq_len, vocab_size)\n",
    "#         layers.LSTM(64),\n",
    "#         # shape-input (NONE, vocab_size)\n",
    "#         layers.Dense(vocab_size, activation=\"softmax\"),\n",
    "#         # bsp out [0.3, 0.2, 0.1, 0.4]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60703971",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 150, 480)          979200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150, 448)          1664768   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               1968128   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29)                14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,626,973\n",
      "Trainable params: 4,626,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4323d5ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standartfunktion Probability array to onehot to integerencoded char \n",
    "# [0.3, 0.2, 0.1, 0.4] -> [0, 0, 0, 1] -> return 4 (stelle, an der 1)\n",
    "def sample(prob, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    prob = np.asarray(prob).astype(\"float64\")\n",
    "    prob = np.log(prob) / temperature\n",
    "    exp_prob = np.exp(prob)\n",
    "    prob = exp_prob / np.sum(exp_prob)\n",
    "    probas = np.random.multinomial(1, prob)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f67c3e-b706-48d3-bb5b-27e67982149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a1e8557",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPOCH:0\n",
      "118/118 [==============================] - 31s 238ms/step - loss: 2.3114 - accuracy: 0.3103\n",
      "\n",
      "kgwotinedretf \n",
      "fwswkiy wasoticn wullf p\n",
      "opta knedyeyaaa tly\n",
      "eotgmrcwiruchtimn\n",
      " eilmsdumjudgfwnytooytvbanyatham;\n",
      "----------------------------------------\n",
      "hovxad araglid\n",
      "mlyfkuzw;\n",
      "----------------------------------------\n",
      "ibe mthmxwirvlnghamnejsnwyywacu\n",
      "wimtcdenpe teauuascm;\n",
      "----------------------------------------\n",
      "wecvamufdida\n",
      "\n",
      "\n",
      "EPOCH:1\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 2.1287 - accuracy: 0.3594\n",
      "\n",
      "tryrnsoocs mendavf;\n",
      "----------------------------------------\n",
      "rkt klmui year sttdy;\n",
      "----------------------------------------\n",
      "ltoldsajtyssid;\n",
      "----------------------------------------\n",
      "sidaoweoery\n",
      "yirirlraaserens\n",
      "doutenhfppugleouvoftterenypmesols\n",
      "facnufstie;\n",
      "----------------------------------------\n",
      "l cily;\n",
      "----------------------------------------\n",
      "twy;\n",
      "----------------------------------------\n",
      "twsat jnfd rfyf;\n",
      "----------------------------------------\n",
      "tavrdbpmy sol yrxuwdhyrifrhtooonisvrypasdsote\n",
      "\n",
      "\n",
      "EPOCH:2\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.9933 - accuracy: 0.3936\n",
      "\n",
      "oannitguflio hyulid;\n",
      "----------------------------------------\n",
      "watoxl grlsaysem xcmamaadth;\n",
      "----------------------------------------\n",
      "bprefo dyraub obtislhinsegy ptpylsu foagtigiughrpnwlf deowesl\n",
      "inoii oafm jatftomiruse dulndtroethyimtamo\n",
      "wiato blmowynesimshienemh lyuubfh agyssdauv;\n",
      "----------------------------------------\n",
      "tha\n",
      "\n",
      "\n",
      "EPOCH:3\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.8814 - accuracy: 0.4230\n",
      "\n",
      "xsotanniyasoouceats ghatmmliny;\n",
      "----------------------------------------\n",
      "ffmtrcchaegnyeips;\n",
      "----------------------------------------\n",
      "ol radivwydrlwmlpotlnshicay ioofyaptsi n yhl\n",
      "edeilvys icmugtblpwoo\n",
      "dhinkamvyrukarniivgoovirnghklevtcvot ryysa\n",
      "yay\n",
      "autifetlsm isslattbtriamys\n",
      "umanerbcp \n",
      "\n",
      "\n",
      "EPOCH:4\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.7826 - accuracy: 0.4503\n",
      "\n",
      "bnalbodyipclioins n\n",
      "pyp crhmiokia\n",
      "ldowildy\n",
      "exal sok yowuy\n",
      "hiovsstsnmopuyvss u gktia\n",
      "wruz olednite jw;\n",
      "----------------------------------------\n",
      "naligvuvpsansv ud\n",
      "wwsakhny\n",
      "nadpvhe \n",
      "lasnaplth;\n",
      "----------------------------------------\n",
      "noymhrtnhew cbvoutat\n",
      "mittleawsjsnslu mklme dyaugcubsi\n",
      "\n",
      "\n",
      "EPOCH:5\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 1.6911 - accuracy: 0.4782\n",
      "\n",
      "fca laudtos lunplzakfrdaz\n",
      "i\n",
      "taah o eciwbyeeairld;\n",
      "----------------------------------------\n",
      "u ca gevupbedaityirfhplbulut i\n",
      "crll gkif dhr pugytbobtoas\n",
      "ct wiktrr gceh pbiir;\n",
      "----------------------------------------\n",
      "soopedeydfwrlpivbsi  ym\n",
      "ukalwisnclssipw fwakp\n",
      "niceurvlrfigcm;\n",
      "----------------------------------------\n",
      "burevattecs\n",
      "\n",
      "\n",
      "EPOCH:6\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.6044 - accuracy: 0.5028\n",
      "\n",
      "ns thm fazrr;\n",
      "----------------------------------------\n",
      "ywyroptbyp checthr;\n",
      "----------------------------------------\n",
      "ste otaymfrtiaroyelese cwuyi;\n",
      "----------------------------------------\n",
      "ynhludidnwsnrrlound;\n",
      "----------------------------------------\n",
      "drhhititnlt;\n",
      "----------------------------------------\n",
      "gwetsptmu owandivp\n",
      " muvpetyontiane avnbugawa\n",
      "vimhnnwagowy;\n",
      "----------------------------------------\n",
      "enofrlwhedsew\n",
      "lef hoclly\n",
      "runnvhrd tutcmaid;\n",
      "----------------------------------------\n",
      "bayu l\n",
      "\n",
      "\n",
      "EPOCH:7\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.5164 - accuracy: 0.5284\n",
      "\n",
      "ukbaill\n",
      " beckmi deidnw mlrpdyelduww yinithmlos hig moxbtake peuportybnyortacksaladyseadedaul\n",
      "lr daspinybtuighd\n",
      "xng ictulksdanm piscli hik tislfava idevuzifu germeikueg bidsio cs\n",
      "cytucmedylerims;\n",
      "----------------------------------------\n",
      "wmbreh\n",
      "\n",
      "\n",
      "EPOCH:8\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.4238 - accuracy: 0.5567\n",
      "\n",
      "rult;\n",
      "----------------------------------------\n",
      "ifnts t exisn wuat i\n",
      "jceevkmbyidfblaa gpdyavscssr\n",
      "takpnriyiguyt;\n",
      "----------------------------------------\n",
      "gytsrynok\n",
      "yigy\n",
      "topmisyoppop\n",
      "hyrowyravowhrrib;\n",
      "----------------------------------------\n",
      "jlsgwtaevessal wwecas byon\n",
      "lloz\n",
      "mesya siis roazaacysmalenkcaose gehaolsigasdlldiscinel\n",
      "\n",
      "\n",
      "EPOCH:9\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.3260 - accuracy: 0.5878\n",
      "\n",
      "sex nwccisnyis movhec\n",
      "putkazcaidfoks harrsntiodhettinnewdotca\n",
      "ripballougdrugsenf\n",
      "fs apaburlcan is oslencpstlpow\n",
      "i sntax at nvipdsecseoncsocpfntoffafum\n",
      "srme fhoseallonagellndinggalef\n",
      "llsuendoiory na fe\n",
      "\n",
      "\n",
      "EPOCH:10\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.2189 - accuracy: 0.6219\n",
      "\n",
      "wikan\n",
      "stky whantrucindpttudemooe ime\n",
      "blhaws j syliiulsntymyrucs;\n",
      "----------------------------------------\n",
      "ontukwsloe go cruebye\n",
      "yagaycwulfrepes toa;\n",
      "----------------------------------------\n",
      "ivrvnynemerfotweywin\n",
      "ewcweanavhenkshecchatur brnnkm\n",
      "latkthrynilknvyrnurao;\n",
      "----------------------------------------\n",
      "hesysodt grwochsslub\n",
      "\n",
      "\n",
      "EPOCH:11\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 1.0946 - accuracy: 0.6654\n",
      "\n",
      "fs r\n",
      "onovumtew ous haing muvsf\n",
      "frrsaqde urpowe\n",
      "diencichenam\n",
      "becnigufedbljfod demn davsidigoldyhh;\n",
      "----------------------------------------\n",
      "grummpsirurew nhsoneglt apoid;\n",
      "----------------------------------------\n",
      "wukndertsodivanc;\n",
      "----------------------------------------\n",
      "y dfoukchwech asdow bldauv\n",
      "sln wuxkovuyty;\n",
      "----------------------------------------\n",
      "ta lemrey tus \n",
      "\n",
      "\n",
      "EPOCH:12\n",
      "118/118 [==============================] - 28s 238ms/step - loss: 0.9654 - accuracy: 0.7090\n",
      "\n",
      "ugsmatstifsfdvissivaxic\n",
      "hsgywtaneycitsdlwaintwreenht arnsis\n",
      "ox fxnpwil exromyne;\n",
      "----------------------------------------\n",
      "twlbwonet skidbwonfuyynlie\n",
      "cpigeidatylulpallwtmy bwosgh mastyserb\n",
      "fanigins iglbuls wpiblal;\n",
      "----------------------------------------\n",
      "hath itncourieff\n",
      "blcoa nhairh\n",
      "\n",
      "\n",
      "EPOCH:13\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.8249 - accuracy: 0.7594\n",
      "\n",
      "upklolodelsa go\n",
      " ib blemfifwoootldirhwsmy\n",
      "tinnslowth tike fumwmow\n",
      "dsecsapmucichod;\n",
      "----------------------------------------\n",
      "fbludhermelabsi\n",
      "smefbilbiplosslelpenorclss\n",
      "t\n",
      "deyri floelsnh trgsoo\n",
      "chasnfogycilo vubheyd twrst\n",
      " ginacickukpelwwaskiovo\n",
      "\n",
      "\n",
      "EPOCH:14\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.6822 - accuracy: 0.8105\n",
      "\n",
      "lun dearllwul\n",
      "amooofof;\n",
      "----------------------------------------\n",
      "plyiindsieflabksath oogecolpy famsoscplikabses\n",
      "pircwhonvenctol uwwos;\n",
      "----------------------------------------\n",
      "shoogs kamfsfar iw\n",
      " qruzgis fewtanoisdalbik buke\n",
      "wimhrutysumlemagttwlltwoistiol\n",
      "gaodaw r keavoer elforchavao\n",
      "\n",
      "\n",
      "EPOCH:15\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.5367 - accuracy: 0.8625\n",
      "\n",
      "vrnoor ivs tagb\n",
      "\n",
      "orf h h bilfrazefvuckme gwwh\n",
      "ieesvareasse;\n",
      "----------------------------------------\n",
      "ogreage accgwwwys wepep\n",
      " morcimfvy myrwceal\n",
      "glevor hryided;\n",
      "----------------------------------------\n",
      "trenindydymylo swa\n",
      "my wrhwied robolys cugisas\n",
      "cy hapiopreminop\n",
      "tlyrsiwssolvukulupi\n",
      "\n",
      "\n",
      "EPOCH:16\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.4014 - accuracy: 0.9066\n",
      "\n",
      "gheme yaglucrds dudys;\n",
      "----------------------------------------\n",
      "qvogysrloodwhonn;\n",
      "----------------------------------------\n",
      "wedknaseflp pled\n",
      "uaksivarpsiof necaru\n",
      "orfbemsmymfeewsdrials;\n",
      "----------------------------------------\n",
      "jeynbanssiald\n",
      "y dysysaflaxess\n",
      "ogdsecweeniidilss\n",
      "ahtlywely;\n",
      "----------------------------------------\n",
      "dcjecdipbvarkanbuw lefertsood mobecs;\n",
      "----------------------------------------\n",
      "so clo\n",
      "\n",
      "\n",
      "EPOCH:17\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.2819 - accuracy: 0.9440\n",
      "\n",
      "qbivibvigttsdri\n",
      " wluverwerddul twpugina\n",
      "yo\n",
      "unetolootoboyr yo;\n",
      "----------------------------------------\n",
      "resey\n",
      "frtidaowyyuwy buhy;\n",
      "----------------------------------------\n",
      "looer yy;\n",
      "----------------------------------------\n",
      "mysuedover\n",
      "wlipivowiwevrysolp enela\n",
      "whaf friebyw shys tusey ;\n",
      "----------------------------------------\n",
      "offfumivy\n",
      "wrak brackows\n",
      "wubi astin teetsalf;\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "EPOCH:18\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.1880 - accuracy: 0.9705\n",
      "\n",
      "ohflvyiowhlwessys\n",
      "\n",
      "yvulvemsed extrukily\n",
      "bnaxy abuau;\n",
      "----------------------------------------\n",
      "if yetreyd\n",
      "yrymworous ugslinydop\n",
      "swuekey;\n",
      "----------------------------------------\n",
      "e bldanchict\n",
      "cr butillby\n",
      "boocsubliov dis;\n",
      "----------------------------------------\n",
      "feecr aftaxineltlesc\n",
      "wisnpurzelilln ishnvared isnpsovpelwodesernee\n",
      "\n",
      "\n",
      "EPOCH:19\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.1267 - accuracy: 0.9827\n",
      "\n",
      "wockvuse;\n",
      "----------------------------------------\n",
      "iwsopmbactistsdive kvrwwsaper oh keptsnaemodenerrun;\n",
      "----------------------------------------\n",
      "afozeiciebywyopewsha\n",
      "futhluits feem tho lsgkendsdet;\n",
      "----------------------------------------\n",
      "ifseoro seafokylh behtend;\n",
      "----------------------------------------\n",
      "a sal llfwistlaniongto;\n",
      "----------------------------------------\n",
      "accmjoffus parafbusedsikbeet\n",
      "ejlex dre\n",
      "\n",
      "\n",
      "EPOCH:20\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.0866 - accuracy: 0.9900\n",
      "\n",
      "un boirhe ibpaicedyntthis\n",
      "fuhbe thaup frad mentepless\n",
      "sodiomofbty\n",
      "ickakid;\n",
      "----------------------------------------\n",
      "fupte us owfprentesnvo\n",
      "untlrygivoridyvody emurhfll\n",
      "owallayynyoourlvnom\n",
      "dxy hlow\n",
      "dappioltibgele wipcegsa\n",
      " ivabvizebmak axssghim\n",
      "\n",
      "\n",
      "EPOCH:21\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.0650 - accuracy: 0.9925\n",
      "\n",
      "abs\n",
      "bidt box shss omi;\n",
      "----------------------------------------\n",
      "berbwhoor tregrepp\n",
      "astodun epet int gry yeg goin\n",
      "to tumicixiog rysuc;\n",
      "----------------------------------------\n",
      "terpmucchizfer fiml\n",
      "bvovier earaizy;\n",
      "----------------------------------------\n",
      "mumita jrevandewset\n",
      "lyares bnfrwes mazacice;\n",
      "----------------------------------------\n",
      "papelif klnwinkmelsoreg\n",
      "vadsl\n",
      "\n",
      "\n",
      "EPOCH:22\n",
      " 54/118 [============>.................] - ETA: 15s - loss: 0.0485 - accuracy: 0.9946"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyModelTuner.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " epochs = 30\n",
    " batch_size = 512\n",
    "\n",
    " input_data = x\n",
    " output_data = y\n",
    "\n",
    "\n",
    " for epoch in range(epochs):\n",
    "     print()\n",
    "     print()\n",
    "     print(f\"EPOCH:{epoch}\")\n",
    "     model.fit(input_data, output_data, batch_size=batch_size, epochs=1)\n",
    "    \n",
    "     model.save('myModelTuner.h5')\n",
    "\n",
    "     print()\n",
    "\n",
    "     generate_chars = 200\n",
    "     temperature = 1.0\n",
    "     start_index = random.randint(0, len(text) - seq_len - 1)\n",
    "     generated = \"\"\n",
    "\n",
    "     seed =  text[start_index : start_index + seq_len]\n",
    "    \n",
    "     #print('...Generating with seed: \"' + seed + '\"')\n",
    "\n",
    "     for i in range(generate_chars):\n",
    "         x_pred = np.zeros((1, len(seed), vocab_size))\n",
    "         for t, char in enumerate(seed):\n",
    "             x_pred[0, t, char_indices[char]] = 1\n",
    "         preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "         next_index = sample(preds, temperature)\n",
    "         next_char = indices_char[next_index]\n",
    "         seed = seed[1:] + next_char\n",
    "         generated += next_char\n",
    "        \n",
    "         if next_char == \";\":\n",
    "             generated += \"\\n----------------------------------------\\n\"\n",
    "            \n",
    "     print(generated) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93fe7191-aaf2-44f9-93c1-3c2b026226d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myModelTuner.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2343e975-ba2e-4874-a953-1ec4242fd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('myModelTuner.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ced3c2d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generating with seed: \"of killing my self\n",
      "i just kinda died;daily reminder\n",
      " that im yellow ranger go\n",
      "go power rangers;i met the finest\n",
      " white man today i think thats\n",
      "gone be\"\n",
      " anoones;\n",
      "----------------------------------------\n",
      "can arl migcasss\n",
      " me lare this is got me\n",
      "on hasss say stopers;\n",
      "----------------------------------------\n",
      "no whis years\n",
      " sometimes i get seed me\n",
      "can smeling hore;\n",
      "----------------------------------------\n",
      "him finally dad\n",
      " can caplent hopes many its\n",
      "not a right with;\n",
      "----------------------------------------\n",
      "i wanna ghou\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_chars = 200\n",
    "temperature = 0.001\n",
    "start_index = random.randint(0, len(text) - seq_len - 1)\n",
    "generated = \"\"\n",
    "\n",
    "seed =  text[start_index : start_index + seq_len]\n",
    "    \n",
    "print('...Generating with seed: \"' + seed + '\"')\n",
    "\n",
    "    \n",
    "for i in range(generate_chars):\n",
    "    x_pred = np.zeros((1, len(seed), vocab_size))\n",
    "    for t, char in enumerate(seed):\n",
    "        x_pred[0, t, char_indices[char]] = 1\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "    seed = seed[1:] + next_char\n",
    "    generated += next_char\n",
    "        \n",
    "    if next_char == \";\":\n",
    "            generated += \"\\n----------------------------------------\\n\"\n",
    "            \n",
    "print(generated) \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfe2ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5075b-d863-43d8-bf7f-a40c2d9306c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

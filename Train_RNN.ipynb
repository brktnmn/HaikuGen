{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfb0df2-6691-42f0-a537-06a1ffbfd9a7",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7d1ec-28ab-4353-9de5-9d0102b0d061",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "203148e5-af60-4988-b678-bda538d6249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d02a6e-d7e4-49bb-85a8-db2d70189bb6",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0c39059e-77d5-42d6-bdce-766e49e9f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd8388-e4bc-4b0b-b6f2-c8ab37360f92",
   "metadata": {},
   "source": [
    "## Transform df to get array of poems (1 input to start with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f19816b9-d18a-4c52-bda3-7aef12cb0867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['0', '1', '2']].agg(lambda x: '\\n'.join(x.values), axis=1)\n",
    "array_of_poems = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef77b0b-c3eb-45bc-b27e-e70603e47602",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Show array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3c8f1528-3578-45c6-aee5-83d9283cd081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last red in the sky\n",
      "a small girls moon face rises\n",
      "over the counter\n",
      "\n",
      "\n",
      "christmas services\n",
      "a cellular phone rings out\n",
      "handels messiah\n",
      "\n",
      "\n",
      "passover darkness \n",
      "before the buds burst open\n",
      "a childs eyes in death\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(array_of_poems):\n",
    "    if i == 3:\n",
    "        break;\n",
    "    print(sentence)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a55c3-9341-464d-a6cb-629710f97792",
   "metadata": {},
   "source": [
    "## Extend poems to match longest poem to get unified length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b943f868-353f-4e23-acb9-835ceb13b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(max(array_of_poems, key = len))\n",
    "\n",
    "for i in range(len(array_of_poems)):\n",
    "    array_of_poems[i] = array_of_poems[i].ljust(maxlen) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0834b0c-61b3-4c4b-8214-96f2e4681539",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Show array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e3ddcbdd-9e83-4844-aa4b-7372df484c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "\n",
      "\n",
      "103\n",
      "\n",
      "\n",
      "103\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(array_of_poems):\n",
    "    if i == 3:\n",
    "        break;\n",
    "    print(len(sentence))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34535e9-892b-41b4-b2cb-a89c60fdfcfb",
   "metadata": {},
   "source": [
    "## Get unique chars in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "05d688c4-b56f-46fc-a88c-862b2ef63d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 unique chars\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(array_of_poems)))\n",
    "print(f'{len(vocab)} unique chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c2cba88a-0204-4aef-9740-b90475160f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780c6d3-b47f-4401-879f-1c6954f507fa",
   "metadata": {},
   "source": [
    "## Before training, convert strings to numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e0dd79-f02e-45e2-ab2b-4a0042e6da95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:34:12.736829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:12.782502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:12.784533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:12.785382: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-25 10:34:12.786514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:12.787089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:12.787446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:13.836433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:13.836964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:13.837337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:34:13.837679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6114 MB memory:  -> device: 0, name: GRID V100S-8Q, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'l', b'a', b's', ..., b' ', b' ', b' '],\n",
       " [b'c', b'h', b'r', ..., b' ', b' ', b' '],\n",
       " [b'p', b'a', b's', ..., b' ', b' ', b' '],\n",
       " ...,\n",
       " [b'a', b'i', b'n', ..., b' ', b' ', b' '],\n",
       " [b'i', b's', b' ', ..., b' ', b' ', b' '],\n",
       " [b'w', b'a', b'n', ..., b' ', b' ', b' ']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = tf.strings.unicode_split(array_of_poems, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a257c09-de11-44dc-9bf1-65da8f30b195",
   "metadata": {},
   "source": [
    "### Create layers for model to transform ids from chars and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeeb9e49-92b3-47d9-8c1f-b8527fa21704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[19, 8, 26, ..., 2, 2, 2],\n",
       " [10, 15, 25, ..., 2, 2, 2],\n",
       " [23, 8, 26, ..., 2, 2, 2],\n",
       " ...,\n",
       " [8, 16, 21, ..., 2, 2, 2],\n",
       " [16, 26, 2, ..., 2, 2, 2],\n",
       " [30, 8, 21, ..., 2, 2, 2]]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31f262e-2871-4327-b054-dd6022d08312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'l', b'a', b's', ..., b' ', b' ', b' '],\n",
       " [b'c', b'h', b'r', ..., b' ', b' ', b' '],\n",
       " [b'p', b'a', b's', ..., b' ', b' ', b' '],\n",
       " ...,\n",
       " [b'a', b'i', b'n', ..., b' ', b' ', b' '],\n",
       " [b'i', b's', b' ', ..., b' ', b' ', b' '],\n",
       " [b'w', b'a', b'n', ..., b' ', b' ', b' ']]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d86a5-7fb0-4fd6-a8b2-252e5bd1855d",
   "metadata": {},
   "source": [
    "### Function to join chars back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d4dea8-7eb2-49e4-af72-c06b3c0082fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d06f3-d491-4191-b500-82ebd73a668a",
   "metadata": {},
   "source": [
    "## Create training example and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef810518-5de7-4aa5-826d-045fd647ede3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poems = ''.join(array_of_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e61a80-5733-4e62-92a6-826b3fc94ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(poems, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcff27f-7c2c-4076-8527-59a38defbad2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "a\n",
      "s\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "k\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      " \n",
      "s\n",
      "m\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "g\n",
      "i\n",
      "r\n",
      "l\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "s\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(93):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a511aae1-502b-48c3-9d66-03b84accc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 92\n",
    "examples_per_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94b6e93-567a-439d-908d-b1da4864271a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48587d8e-db68-45b4-aea5-eb1f3ccf8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c227bff-2c06-40f4-bf02-1c77d314898a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'last red in the sky\\na small girls moon face rises\\nover the counter                          '\n",
      "Target: b'ast red in the sky\\na small girls moon face rises\\nover the counter                           '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc70bbf-d679-4605-9da5-a35f29f57a1b",
   "metadata": {},
   "source": [
    "## Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcf57f7-eccb-4f74-b829-80aca29a7dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 92), dtype=tf.int64, name=None), TensorSpec(shape=(64, 92), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5582f1-650c-44a8-bcd3-022412c9cbd8",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e100036-7f11-4272-8871-e7bfa48a9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78cc3a18-c99f-4237-91fd-5755a8590772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "      def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "      def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.lstm.get_initial_state(x)\n",
    "        x, *states = self.lstm(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0554c10-0e50-46d1-a9da-9cf6426dbba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cc5d9-5666-42c6-9595-358ead8bc8d5",
   "metadata": {},
   "source": [
    "## Try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8160f28-ae68-4a9d-8030-73e308573203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:34:49.090754: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 92, 34) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec282464-e545-461d-be66-3c431c1e97fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  8704      \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  5246976   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  34850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,290,530\n",
      "Trainable params: 5,290,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65c290f5-ed80-4b5e-9c7c-1ec17754f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 92, 34)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.525304, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc30d069-8e49-476e-beb2-fcdc8f8323ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.964104"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c59ace-523b-412e-b645-a47ea801bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8f8bdde-999e-4255-bb5c-15bb21ca179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7020bea0-7c86-4017-acff-3f0ad1205e61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1459/1459 [==============================] - 42s 27ms/step - loss: 1.2989\n",
      "Epoch 2/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.8885\n",
      "Epoch 3/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.8154\n",
      "Epoch 4/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.7786\n",
      "Epoch 5/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.7518\n",
      "Epoch 6/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.7299\n",
      "Epoch 7/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.7105\n",
      "Epoch 8/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.6925\n",
      "Epoch 9/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.6759\n",
      "Epoch 10/10\n",
      "1459/1459 [==============================] - 40s 27ms/step - loss: 0.6604\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, use_multiprocessing=True, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7ea6ea7a-2ac6-4af0-a927-297df6918f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=0.6):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                              return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c23e7bf0-e936-44fb-9c3a-dfc7e5d5b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12aee7cc-585f-49e0-8be3-e33cacb8491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def generateHaikus(charList: List):\n",
    "    start = time.time()\n",
    "    states = None\n",
    "    next_char = tf.constant(charList)\n",
    "    result = [next_char]\n",
    "\n",
    "    for n in range(93):\n",
    "        next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "        result.append(next_char)\n",
    "\n",
    "    result = tf.strings.join(result)\n",
    "    end = time.time()\n",
    "    print(result[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26b8e139-d365-4a06-a5c8-bd409c3d18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "just watched the issue make it\n",
      "spend time with your boo                                      \n",
      "\n",
      "\n",
      "                                                                                              \n",
      "\n",
      "\n",
      "0ate less than anyone\n",
      "who really cant handle the\n",
      "time he was a bit                            \n",
      "\n",
      "\n",
      "1_00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "\n",
      "\n",
      "3the best thing about\n",
      "me is having a pair of\n",
      "point in the morning                             \n",
      "\n",
      "\n",
      "9emes if someone comes\n",
      "to the truth if you do that\n",
      "field some day today                       \n",
      "\n",
      "\n",
      "_ri and my ethict is\n",
      "a game now i have to watch\n",
      "the best for a word                           \n",
      "\n",
      "\n",
      "apparently its\n",
      "fair has to be a shit now\n",
      "i just want to die                                   \n",
      "\n",
      "\n",
      "but you gotta thank\n",
      "you for what you did to be\n",
      "a day forever                                  \n",
      "\n",
      "\n",
      "can agree with the\n",
      "royal wedding there are for\n",
      "the rest of the day                            \n",
      "\n",
      "\n",
      "dont worry it is\n",
      "a lot of conversation\n",
      "people sorry same                                      \n",
      "\n",
      "\n",
      "everyone starts to\n",
      "love science that they like to\n",
      "be with their tickets                       \n",
      "\n",
      "\n",
      "first time in perfect\n",
      "day im excited for the\n",
      "rest of the weekend                              \n",
      "\n",
      "\n",
      "good morning to all\n",
      "the people in the morning\n",
      "so thats the future                             \n",
      "\n",
      "\n",
      "has anyone can\n",
      "help with a lot of shit on\n",
      "me im the best part                                 \n",
      "\n",
      "\n",
      "i wont ever be\n",
      "as good as my mans whole day\n",
      "is going to be                                    \n",
      "\n",
      "\n",
      "jesus christ is what\n",
      "i have to stop being but\n",
      "not as hard in space                            \n",
      "\n",
      "\n",
      "knowing im like i\n",
      "wont even be alone should\n",
      "make my heart feel it                             \n",
      "\n",
      "\n",
      "love is not going\n",
      "to be a good show cause i\n",
      "know its finally                                  \n",
      "\n",
      "\n",
      "man and even though\n",
      "he cant stop being a close\n",
      "the concept of you                             \n",
      "\n",
      "\n",
      "need to go back to\n",
      "christmas shopping so i can\n",
      "hear my mind again                             \n",
      "\n",
      "\n",
      "of course felix is\n",
      "better than a thousand stuff\n",
      "in the hard of you                            \n",
      "\n",
      "\n",
      "putting me on will\n",
      "i start studying about\n",
      "being a great day                                   \n",
      "\n",
      "\n",
      "question is not a\n",
      "good rad should be a shit hole\n",
      "in a sunday lol                              \n",
      "\n",
      "\n",
      "really hope u have\n",
      "a battle of drama im\n",
      "the only one who                                      \n",
      "\n",
      "\n",
      "she is a doctor\n",
      "sacring me now i just woke\n",
      "up sick of im stressed                             \n",
      "\n",
      "\n",
      "the professor of\n",
      "the doctor white house that beats\n",
      "the halloween off                          \n",
      "\n",
      "\n",
      "ugh really put me\n",
      "in the mood for the change i\n",
      "was a lazy thing                               \n",
      "\n",
      "\n",
      "very therapy\n",
      "to be the first time on the\n",
      "good place in the face                               \n",
      "\n",
      "\n",
      "why is my little\n",
      "brother so i would get through\n",
      "no sense on my friends                        \n",
      "\n",
      "\n",
      "x dancer leagues\n",
      "he is a fucking disgust\n",
      "i promise you too                                    \n",
      "\n",
      "\n",
      "you will never be\n",
      "a shit that people dont stay\n",
      "in your life with you                          \n",
      "\n",
      "\n",
      "zodies should not be\n",
      "anymore else and or is\n",
      "it just something now                             \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in vocab:\n",
    "    generateHaikus([el])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "568c61db-ce7a-402e-b505-8582c2b7fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you do not believe\n",
      "in yourself but you have to\n",
      "go to the beach too                            \n",
      "\n",
      "Run time: 0.21434712409973145\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['y'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(93):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'))\n",
    "print('\\nRun time:', end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
